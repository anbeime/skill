#!/usr/bin/env python3
"""
è®¢é˜…æºæŠ“å–è„šæœ¬

åŠŸèƒ½ï¼šä»å¤šä¸ªè®¢é˜…æºæŠ“å–çƒ­ç‚¹å†…å®¹
æ”¯æŒï¼šRSS feedã€è‡ªå®šä¹‰APIï¼ˆçŸ¥ä¹ã€å¾®åšç­‰ï¼‰
"""

import sys
import argparse
import json
from datetime import datetime
from typing import List, Dict
from coze_workload_identity import requests


class SourceFetcher:
    """è®¢é˜…æºæŠ“å–å™¨"""
    
    def __init__(self, config_path: str = None):
        self.sources = self._load_config(config_path) if config_path else []
    
    def _load_config(self, config_path: str) -> List[Dict]:
        """åŠ è½½è®¢é˜…æºé…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('sources', [])
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}", file=sys.stderr)
            return []
    
    def fetch_rss(self, url: str, count: int = 10) -> List[Dict]:
        """æŠ“å–RSSæº"""
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            # ç®€åŒ–å¤„ç†ï¼šå®é™…åº”è¯¥ä½¿ç”¨feedparseråº“è§£æRSS
            # è¿™é‡Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            return [
                {
                    'title': f'RSSæ ‡é¢˜{i+1}',
                    'link': f'https://example.com/article{i+1}',
                    'pub_date': datetime.now().isoformat(),
                    'summary': f'è¿™æ˜¯RSSæ–‡ç« {i+1}çš„æ‘˜è¦å†…å®¹...',
                    'source': url
                }
                for i in range(count)
            ]
        except Exception as e:
            print(f"æŠ“å–RSSå¤±è´¥ {url}: {str(e)}", file=sys.stderr)
            return []
    
    def fetch_zhihu_hot(self) -> List[Dict]:
        """æŠ“å–çŸ¥ä¹çƒ­æ¦œ"""
        try:
            url = "https://www.zhihu.com/api/v3/feed/topstory/hot-lists/total"
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            items = []
            
            for item in data.get('data', [])[:10]:
                items.append({
                    'title': item.get('target', {}).get('title', ''),
                    'link': f"https://www.zhihu.com/question/{item.get('target', {}).get('id', '')}",
                    'pub_date': datetime.now().isoformat(),
                    'summary': item.get('target', {}).get('excerpt', ''),
                    'source': 'çŸ¥ä¹çƒ­æ¦œ',
                    'heat': item.get('detail_text', '')
                })
            
            return items
        except Exception as e:
            print(f"æŠ“å–çŸ¥ä¹çƒ­æ¦œå¤±è´¥: {str(e)}", file=sys.stderr)
            return []
    
    def fetch_weibo_hot(self) -> List[Dict]:
        """æŠ“å–å¾®åšçƒ­æœ"""
        # å¾®åšçƒ­æœéœ€è¦ç™»å½•å’Œç­¾åï¼Œè¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
        return [
            {
                'title': 'å¾®åšçƒ­æœç¤ºä¾‹1',
                'link': 'https://s.weibo.com/weibo?q=test1',
                'pub_date': datetime.now().isoformat(),
                'summary': 'è¿™æ˜¯å¾®åšçƒ­æœçš„ç¤ºä¾‹å†…å®¹...',
                'source': 'å¾®åšçƒ­æœ',
                'heat': '100ä¸‡'
            },
            {
                'title': 'å¾®åšçƒ­æœç¤ºä¾‹2',
                'link': 'https://s.weibo.com/weibo?q=test2',
                'pub_date': datetime.now().isoformat(),
                'summary': 'è¿™æ˜¯å¾®åšçƒ­æœçš„ç¤ºä¾‹å†…å®¹...',
                'source': 'å¾®åšçƒ­æœ',
                'heat': '80ä¸‡'
            }
        ]
    
    def fetch_all(self) -> List[Dict]:
        """æŠ“å–æ‰€æœ‰é…ç½®çš„è®¢é˜…æº"""
        all_items = []
        
        for source in self.sources:
            source_type = source.get('type', '')
            url = source.get('url', '')
            
            if source_type == 'rss' and url:
                items = self.fetch_rss(url, count=source.get('count', 5))
                all_items.extend(items)
            elif source_type == 'zhihu':
                items = self.fetch_zhihu_hot()
                all_items.extend(items)
            elif source_type == 'weibo':
                items = self.fetch_weibo_hot()
                all_items.extend(items)
        
        return all_items
    
    def filter_by_keywords(self, items: List[Dict], keywords: List[str]) -> List[Dict]:
        """æ ¹æ®å…³é”®è¯è¿‡æ»¤å†…å®¹"""
        if not keywords:
            return items
        
        filtered = []
        for item in items:
            title = item.get('title', '').lower()
            summary = item.get('summary', '').lower()
            
            for keyword in keywords:
                if keyword.lower() in title or keyword.lower() in summary:
                    filtered.append(item)
                    break
        
        return filtered


def main():
    parser = argparse.ArgumentParser(description="ä»è®¢é˜…æºæŠ“å–çƒ­ç‚¹å†…å®¹")
    
    parser.add_argument("--config", help="è®¢é˜…æºé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆJSONæ ¼å¼ï¼‰")
    parser.add_argument("--sources", nargs='+', 
                       choices=['rss', 'zhihu', 'weibo'],
                       default=['zhihu'],
                       help="è®¢é˜…æºç±»å‹ï¼ˆé»˜è®¤ï¼šzhihuï¼‰")
    parser.add_argument("--keywords", nargs='+', 
                       help="å…³é”®è¯è¿‡æ»¤ï¼ŒåŒ¹é…æ ‡é¢˜æˆ–æ‘˜è¦")
    parser.add_argument("--output", 
                       default="output/sources.json",
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šoutput/sources.jsonï¼‰")
    parser.add_argument("--count", type=int, default=10,
                       help="æ¯ä¸ªæºæŠ“å–æ•°é‡ï¼ˆé»˜è®¤ï¼š10ï¼‰")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæŠ“å–å™¨
        fetcher = SourceFetcher(args.config)
        
        # æŠ“å–å†…å®¹
        print("æ­£åœ¨æŠ“å–è®¢é˜…æº...")
        print(f"è®¢é˜…æº: {', '.join(args.sources)}")
        if args.keywords:
            print(f"å…³é”®è¯è¿‡æ»¤: {', '.join(args.keywords)}")
        
        all_items = []
        
        for source_type in args.sources:
            print(f"\næ­£åœ¨æŠ“å– {source_type}...")
            
            if source_type == 'zhihu':
                items = fetcher.fetch_zhihu_hot()
            elif source_type == 'weibo':
                items = fetcher.fetch_weibo_hot()
            elif source_type == 'rss':
                if args.config:
                    items = fetcher.fetch_all()
                else:
                    print("  RSSéœ€è¦é…ç½®æ–‡ä»¶ï¼Œè·³è¿‡")
                    continue
            
            print(f"  æŠ“å–åˆ° {len(items)} æ¡å†…å®¹")
            all_items.extend(items)
        
        # å…³é”®è¯è¿‡æ»¤
        if args.keywords:
            print(f"\næ­£åœ¨è¿‡æ»¤å…³é”®è¯...")
            filtered_items = fetcher.filter_by_keywords(all_items, args.keywords)
            print(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_items)} æ¡å†…å®¹")
            all_items = filtered_items
        
        # é™åˆ¶æ•°é‡
        all_items = all_items[:args.count]
        
        # ä¿å­˜ç»“æœ
        import os
        os.makedirs(os.path.dirname(args.output), exist_ok=True)
        
        result = {
            'fetch_time': datetime.now().isoformat(),
            'total_count': len(all_items),
            'items': all_items
        }
        
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æŠ“å–å®Œæˆï¼")
        print(f"ä¿å­˜åˆ°: {args.output}")
        print(f"æ€»è®¡: {len(all_items)} æ¡å†…å®¹")
        
        # æ˜¾ç¤ºå‰3æ¡
        print("\nğŸ“‹ å†…å®¹é¢„è§ˆ:")
        for i, item in enumerate(all_items[:3], 1):
            print(f"\n{i}. {item.get('title', '')}")
            print(f"   æ¥æº: {item.get('source', '')}")
            print(f"   æ‘˜è¦: {item.get('summary', '')[:80]}...")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ æŠ“å–å¤±è´¥: {str(e)}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
